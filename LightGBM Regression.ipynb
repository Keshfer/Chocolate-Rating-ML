{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f6f6c105-3ef7-4ebe-833e-3c8e18fd63f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6f6c105-3ef7-4ebe-833e-3c8e18fd63f7",
        "outputId": "5d2b437f-851a-41d2-8ec7-c75fa4093429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Keshfer/Chocolate-Rating-ML"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzumaDvAFRl1",
        "outputId": "90543fc9-db06-4fb1-adc7-98fdb1776f57"
      },
      "id": "QzumaDvAFRl1",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Chocolate-Rating-ML'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 77 (delta 40), reused 50 (delta 22), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (77/77), 3.43 MiB | 19.28 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Chocolate-Rating-ML"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtTR2yU0FgWX",
        "outputId": "a426f1dd-12e7-460e-8682-49b9c8cf7529"
      },
      "id": "dtTR2yU0FgWX",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Chocolate-Rating-ML\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bca2e9b7-72f6-44b2-8310-6c29511b082f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bca2e9b7-72f6-44b2-8310-6c29511b082f",
        "outputId": "52e1da0a-ec00-433c-a7b4-a98e9cdd1f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed__0', 'REF', 'Review_Date', 'Cocoa_Percent',\n",
            "       'Company_Location_AF', 'Company_Location_AS', 'Company_Location_CA',\n",
            "       'Company_Location_CEU', 'Company_Location_CR', 'Company_Location_EEU',\n",
            "       'Company_Location_NA', 'Company_Location_OC', 'Company_Location_SA',\n",
            "       'Company_Location_WEU', 'Broad_Bean_Origin_AF', 'Broad_Bean_Origin_AS',\n",
            "       'Broad_Bean_Origin_CA', 'Broad_Bean_Origin_CR', 'Broad_Bean_Origin_NA',\n",
            "       'Broad_Bean_Origin_OC', 'Broad_Bean_Origin_SA',\n",
            "       'Broad_Bean_Origin_Unknown'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Import approriate functions and packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import the dataframe\n",
        "df = pd.read_csv('cacao_engineered.csv')\n",
        "\n",
        "# Create X and y training and testing data\n",
        "X = df.drop(['Rating'], axis=1)\n",
        "y = df['Rating']\n",
        "\n",
        "# Clean up columns of X so it works with the model\n",
        "X.columns = [col.replace(\" \", \"_\").replace(\":\", \"_\") for col in X.columns]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start creating lgb regression model\n",
        "# Create the lgb Dataset objects to store the training and testing data\n",
        "train_data = lgb.Dataset(X_train, label = y_train)\n",
        "test_data = lgb.Dataset(X_test, label = y_test, reference=train_data)\n",
        "\n",
        "# Set parameters for the lgb regression model\n",
        "# Objective: Set to regression so that the model tries to predict a regressive value (in this case, quality)\n",
        "# Metric: The loss metric to be used for the model. Set to mse for now.\n",
        "# Learning rate: How much to update the trees when refining\n",
        "# Feature fraction: The percentage of features to take into account when making model, used to prevent overfitting\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'mse',\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "}\n",
        "\n",
        "# Train the actual model, passes in the parameters, training data, the number of rounds to train\n",
        "num_round = 100  # Number of boosting rounds\n",
        "model = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    num_boost_round=num_round,\n",
        "    valid_sets=[train_data, test_data],\n",
        "    valid_names=['train', 'eval'],\n",
        ")\n",
        "\n",
        "# Predict on the test set, using the best iteration of the model for training\n",
        "y_pred = model.predict(X_test, num_iteration = model.best_iteration)\n",
        "\n",
        "# Calculate MSE\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"MSE: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOngRBU2FyTU",
        "outputId": "5505eaa0-8c7d-4dc0-b5ab-55366f89918b"
      },
      "id": "uOngRBU2FyTU",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001750 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 582\n",
            "[LightGBM] [Info] Number of data points in the train set: 1436, number of used features: 21\n",
            "[LightGBM] [Info] Start training from score 3.189763\n",
            "MSE: 0.19547680507452356\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}