{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68fd242d-d8d7-4dfe-9662-7b609c3e71c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataset: (1795, 23)\n",
      "Mean Squared Error 0.19062630846325165\n",
      "Root Mean Squared Error 0.43660772835951\n",
      "Adjusted R Squared Score:  0.15955653902878442\n",
      "Mean Absolute Error: 0.08771030640668517\n",
      "Mean Absolute Percentage Error (Accuracy): 11.54331612151769%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('cacao_engineered.csv')\n",
    "print(f\"shape of dataset: {df.shape}\")\n",
    "#split data 75:25\n",
    "x = df.loc[:, df.columns != 'Rating']\n",
    "y = df['Rating']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.75)\n",
    "\n",
    "#Random Forest regression with default values\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "#fit model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#predict on model\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "#evaluate model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error\", mse)\n",
    "\n",
    "rmse = mse**0.5\n",
    "print(\"Root Mean Squared Error\", rmse)\n",
    "\n",
    "r2score = r2_score(y_test, y_pred)\n",
    "#adjusted rscore is just rscore but the rscore can increase with additional features even though no improvement occurs for model's performance. \n",
    "#Basically adjusted negates the weakness of rscore\n",
    "adjusted_r2score = 1- ((1 - r2score) * ((df.shape[0] - 1) / (df.shape[0] - df.shape[1] - 1)))\n",
    "print(\"Adjusted R Squared Score: \", adjusted_r2score)\n",
    "\n",
    "mae = (1/ df.shape[0]) * sum(abs(y_test - y_pred))\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "errors = abs(y_test - y_pred)\n",
    "mape = (1/len(y_test)) * sum(errors / y_test) * 100\n",
    "print(f\"Mean Absolute Percentage Error (Accuracy): {mape}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4abc90-accf-4299-89a9-517cca06bd31",
   "metadata": {},
   "source": [
    "Above output is from the Random Forest Regression with the default settings. Currently, according to the Adjusted R Squared Score, the model is not performing well since it has a score close to 0. In other words, the features currently do not predict the ratings very well. This is further supported by the low accuracy. The Mean Squared Error, Root Mean Squared Error, and Mean Absolute Error currently don't have much meaning since we don't have other measurements to compare them to. So let's try using grid search to see parameters work best for Random Forest Regression. Let's first see what range of parameter works best for our model using Random Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5de688e0-d6f9-44d8-9cab-028f8253b012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataset: (1795, 23)\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "\n",
      "\n",
      "Best parameters from Random Search: {'n_estimators': 600, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_samples': None, 'max_features': 'sqrt', 'max_depth': 40}\n",
      "Mean Squared Error 0.29704891425389757\n",
      "Root Mean Squared Error 0.5450219392408874\n",
      "Adjusted R Squared Score:  -0.2495004381924424\n",
      "Mean Absolute Percentage Error (Accuracy): 14.374450580352605%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('cacao_engineered.csv')\n",
    "print(f\"shape of dataset: {df.shape}\")\n",
    "#split data 75:25\n",
    "x = df.loc[:, df.columns != 'Rating']\n",
    "y = df['Rating']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.75)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "print(model.get_params())\n",
    "param_grid = {\n",
    "    'max_samples': [None, 5 ,20, 50 , 80, 100, 200],\n",
    "    'max_depth': [None, 10,20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'max_features': ['sqrt', 'log2', 1],\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    'min_samples_split': [2,3,5, 6, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4 , 5, 6, 7,8,9, 10]\n",
    "}\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=200, cv=5, error_score='raise', verbose=3, n_jobs=-1)\n",
    "random_search.fit(x_train, y_train)\n",
    "print('\\n')\n",
    "print(f\"Best parameters from Random Search: {random_search.best_params_}\")\n",
    "\n",
    "model_rand_params = random_search.best_estimator_\n",
    "model_rand_params.predict(x_test)\n",
    "#evaluate model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error\", mse)\n",
    "\n",
    "rmse = mse**0.5\n",
    "print(\"Root Mean Squared Error\", rmse)\n",
    "\n",
    "r2score = r2_score(y_test, y_pred)\n",
    "#adjusted rscore is just rscore but the rscore can increase with additional features even though no improvement occurs for model's performance. \n",
    "#Basically adjusted negates the weakness of rscore\n",
    "adjusted_r2score = 1- ((1 - r2score) * ((df.shape[0] - 1) / (df.shape[0] - df.shape[1] - 1)))\n",
    "print(\"Adjusted R Squared Score: \", adjusted_r2score)\n",
    "\n",
    "errors = abs(y_test - y_pred)\n",
    "mape = (1/len(y_test)) * sum(errors / y_test) * 100\n",
    "print(f\"Mean Absolute Percentage Error (Accuracy): {mape}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829f089-0c02-4518-a5ab-48bca6ada5d5",
   "metadata": {},
   "source": [
    "With the best parameters returned, we can use these values to explore nearby values using Grid Search. First, let's examine the performance evaluation for the model using these parameters. Comparing to the default mode, MSE has approximately doubled in value while RMSE has only increase by roughly 0.1. This either means that the predictions have further strayed from the actual values or the change in parameters have exacerbated the outliers in the dataset. Adjusted R Square Score has further worsen now exhibiting a negative value. This means that the model fits the test data horribly, shwoing that the model doesn't capture the test data's pattern at all. Despite the worsening of these metrics, The MAPE shows a small boost. This seems contradictory since an increase an error should indicate a decrease inaccuracy. Let's see if we can gain more insights through Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ac62a-1def-47ae-ac84-81155b56d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importants = list(model.feature_importances_)\n",
    "# important_features = []\n",
    "# df_features = list(x.columns)\n",
    "# for feature, important in zip(df_features, importants):\n",
    "#     important_features.append((feature, important))\n",
    "# important_features = sorted(important_features, key = lambda tuple: tuple[1], reverse=True)\n",
    "# for tuple in important_features:\n",
    "#     print(f\"Variable: {tuple[0]}       Importance:{tuple[1]}\")\n",
    "\n",
    "# #bar graph of the important features\n",
    "# x_values = list(range(len(importants)))\n",
    "# plt.bar(x_values, importants, orientation='vertical') \n",
    "# plt.xticks(x_values, df_features, rotation=45)\n",
    "# plt.xlabel('features')\n",
    "# plt.ylabel('Importance')\n",
    "# plt.title('Feature importances')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "625eed5f-20d7-49fe-860c-06201fa6c9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataset: (1795, 23)\n",
      "Fitting 6 folds for each of 216 candidates, totalling 1296 fits\n",
      "best params for the model are {'max_depth': 30, 'max_features': 'sqrt', 'max_samples': None, 'min_samples_leaf': 1, 'min_samples_split': 7, 'n_estimators': 600}\n",
      "Mean Squared Error 0.17514193129114258\n",
      "Root Mean Squared Error 0.4184996192246088\n",
      "Adjusted R Squared Score:  0.1557685169406693\n",
      "Mean Absolute Percentage Error (Accuracy): 10.952308218649097%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "df = pd.read_csv('cacao_engineered.csv')\n",
    "print(f\"shape of dataset: {df.shape}\")\n",
    "#split data 75:25\n",
    "x = df.loc[:, df.columns != 'Rating']\n",
    "y = df['Rating']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.75)\n",
    "\n",
    "#Random Forest regression with gridsearch values\n",
    "model_grid = RandomForestRegressor()\n",
    "\n",
    "#trying a range of values close to the Random Search parameters\n",
    "\n",
    "param_grid = {\n",
    "    'max_samples': [None, 100, 500, 1000],\n",
    "    'max_depth': [30, 40, 50],\n",
    "    'max_features': ['sqrt'],\n",
    "    'n_estimators': [500, 600, 700],\n",
    "    'min_samples_split': [7,8,9],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator = model_grid, param_grid = param_grid, verbose= 4, cv=6, error_score='raise', n_jobs = -1)\n",
    "grid_result = grid_search.fit(x_train, y_train)\n",
    "print(f\"best params for the model are {grid_search.best_params_}\")\n",
    "\n",
    "#predict on model with best parameters from grid search\n",
    "model_grid_params = grid_search.best_estimator_\n",
    "y_pred = model_grid_params.predict(x_test)\n",
    "#evaluate model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error\", mse)\n",
    "rmse = mse**0.5\n",
    "print(\"Root Mean Squared Error\", rmse)\n",
    "r2score = r2_score(y_test, y_pred)\n",
    "#adjusted rscore is just rscore but the rscore only improves if additional features actually improves the model's performance. \n",
    "#Basically it negates the weakness of rscore which is that the score increases as the number of features increase\n",
    "adjusted_r2score = 1- ((1 - r2score) * ((df.shape[0] - 1) / (df.shape[0] - df.shape[1] - 1)))\n",
    "print(\"Adjusted R Squared Score: \", adjusted_r2score)\n",
    "\n",
    "errors = abs(y_test - y_pred)\n",
    "mape = (1/len(y_test)) * sum(errors / y_test) * 100\n",
    "print(f\"Mean Absolute Percentage Error (Accuracy): {mape}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cfd14d-d29c-4c6d-8061-ca65a2db6be9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
